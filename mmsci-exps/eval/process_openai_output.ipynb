{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename openai output files\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "with open('tmp.txt') as fin:\n",
    "    lines = [line.strip() for line in fin.readlines()]\n",
    "    print(len(lines))\n",
    "    input_filenames = lines[::2]\n",
    "    output_filenames = lines[1::2]\n",
    "    assert len(input_filenames) == len(output_filenames)\n",
    "mapping = {o:i for i, o in zip(input_filenames, output_filenames)}\n",
    "\n",
    "openai_output_dir = './output/openai_output_w_settings'\n",
    "filenames = os.listdir(openai_output_dir)\n",
    "for old_name in filenames:\n",
    "    new_name = mapping[old_name]\n",
    "    shutil.move(\n",
    "        os.path.join(openai_output_dir, old_name), \n",
    "        os.path.join(openai_output_dir, new_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge chunked openai output files\n",
    "from collections import defaultdict\n",
    "merged_output_dir = './output/openai_output_w_settings_merged'\n",
    "os.makedirs(merged_output_dir, exist_ok=True)\n",
    "\n",
    "storing = defaultdict(list)\n",
    "for filename in os.listdir(openai_output_dir):\n",
    "    prefix = '_'.join(filename.split('_')[:-1])\n",
    "    storing[prefix].append(filename)\n",
    "\n",
    "for prefix, file_list in storing.items():\n",
    "    print(prefix)\n",
    "    output_filename = os.path.join(merged_output_dir, f'{prefix}.jsonl')\n",
    "    with open(output_filename, 'w') as fout:\n",
    "        for file in file_list:\n",
    "            # print(file)\n",
    "            with open(os.path.join(openai_output_dir, file), 'r') as fin:\n",
    "                lines = fin.readlines()\n",
    "            fout.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat captioning results\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "base_input_dir = './output/openai_output_w_settings_merged'\n",
    "k = 3\n",
    "task = 'generation'\n",
    "output_dir = f'./output/image_caption_{task}'\n",
    "\n",
    "base_data_dir = '/home/ubuntu/MMSci/mmsci-data/benchmark/test/'\n",
    "input_data = json.load(open(os.path.join(base_data_dir, f'image_caption_{task}_data.json')))\n",
    "input_data_mapping = {i: item for i, item in enumerate(input_data)}\n",
    "\n",
    "def reformat_caption_generation(input_filepath, output_filepath):\n",
    "    output_list = []\n",
    "    with open(input_filepath, 'r') as fin:\n",
    "        for line in fin.readlines():\n",
    "            info = json.loads(line)\n",
    "            key = int(info['custom_id'])\n",
    "            answers = []\n",
    "            for ans_info in info['response']['body'][\"choices\"]:\n",
    "                answers.append(ans_info['message']['content'])\n",
    "            info = input_data_mapping[key]\n",
    "            info['prediction'] = answers\n",
    "            output_list.append(info)\n",
    "    with open(output_filepath, 'w') as fout:\n",
    "        json.dump(output_list, fout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(base_input_dir, f'*{task}*'))\n",
    "\n",
    "for filepath in file_list:\n",
    "    filename = filepath.split('/')[-1]\n",
    "    # print(filename)\n",
    "    model_name = filename.split('_')[0]\n",
    "    w_abs = filename.find('w_abstract') > -1\n",
    "    w_content = filename.find('w_content') > -1\n",
    "    tag = f'abs{str(w_abs)}_ctx{str(w_content)}'\n",
    "    # print(tag, model_name)\n",
    "    reformat_caption_generation(\n",
    "        input_filepath=filepath,\n",
    "        output_filepath=os.path.join(output_dir, tag, f'k_{k}', f'{model_name}.json')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# reformat matching results\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "base_input_dir = './output/openai_output_w_settings_merged'\n",
    "k = 5\n",
    "task = 'matching'\n",
    "output_dir = f'./output/image_caption_{task}'\n",
    "\n",
    "base_data_dir = '/home/ubuntu/MMSci/mmsci-data/benchmark/test/'\n",
    "all_input_data = json.load(open(os.path.join(base_data_dir, f'image_caption_{task}_data.json')))\n",
    "input_data_mapping = defaultdict(dict)\n",
    "for setting, input_data in enumerate(all_input_data):\n",
    "    input_data_mapping[setting+1] = {i: item for i, item in enumerate(input_data)}\n",
    "print(input_data_mapping.keys())\n",
    "\n",
    "def reformat_caption_matching(input_filepath, model_name, tag):\n",
    "    all_output_list = defaultdict(list)\n",
    "    with open(input_filepath, 'r') as fin:\n",
    "        for line in fin.readlines():\n",
    "            info = json.loads(line)\n",
    "            setting, key = info['custom_id'].split('_')  # f'{setting+1}_{str(idx)}'\n",
    "            setting, key = int(setting), int(key)\n",
    "            answers = []\n",
    "            for ans_info in info['response']['body'][\"choices\"]:\n",
    "                answers.append({\n",
    "                    'answer': ans_info['message']['content']\n",
    "                })\n",
    "            info = input_data_mapping[setting][key]\n",
    "            info['prediction'] = answers\n",
    "            all_output_list[setting].append(info)\n",
    "    for setting, output_list in all_output_list.items():\n",
    "        output_filepath = os.path.join(output_dir, tag, f'setting-{setting}', f'k_{k}', f'{model_name}.json')\n",
    "        with open(output_filepath, 'w') as fout:\n",
    "            json.dump(output_list, fout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-turbo_w-cot_image_caption_matching_data.jsonl\n",
      "w_cot gpt-4-turbo\n",
      "gpt-4-turbo_wo-cot_image_caption_matching_data.jsonl\n",
      "wo_cot gpt-4-turbo\n",
      "gpt-4o_wo-cot_image_caption_matching_data.jsonl\n",
      "wo_cot gpt-4o\n",
      "gpt-4o_w-cot_image_caption_matching_data.jsonl\n",
      "w_cot gpt-4o\n"
     ]
    }
   ],
   "source": [
    "file_list = glob.glob(os.path.join(base_input_dir, f'*{task}*'))\n",
    "\n",
    "for filepath in file_list:\n",
    "    filename = filepath.split('/')[-1]\n",
    "    print(filename)\n",
    "    model_name = filename.split('_')[0]\n",
    "    tag = 'w_cot' if filename.find('w-cot') > -1 else 'wo_cot'\n",
    "    print(tag, model_name)\n",
    "    reformat_caption_matching(\n",
    "        input_filepath=filepath, \n",
    "        model_name=model_name, \n",
    "        tag=tag,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mace_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
